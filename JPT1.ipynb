{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxfezSXxd4yi5kAH9fd8x2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as rd"
      ],
      "metadata": {
        "id": "8CgYT4QFt8hm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-YFPgyCzmlY",
        "outputId": "f4c0fd67-6958-4737-daba-2f441329dc7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-02 21:34:01--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  5.10MB/s    in 0.2s    \n",
            "\n",
            "2023-12-02 21:34:02 (5.10 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Importing the dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read it to inspect it\n",
        "with open('input.txt','r',encoding='utf-8') as f:\n",
        "  text=f.read()"
      ],
      "metadata": {
        "id": "5Gdpf691t4TE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Length of dataset in characters : \", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d_NzM77t8zB",
        "outputId": "3f1892af-cfa2-43d2-d8e7-6b25e9af501d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of dataset in characters :  1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dm89Rf1ot8r_",
        "outputId": "2c953803-be7a-4972-f93e-54aad57966d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMSO9ERTt8o0",
        "outputId": "4ce2ef8f-4533-400d-c328-9fa27fa17b77"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mapping des caractères en entiers\n",
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "encode = lambda s : [stoi[i] for i in s]\n",
        "decode = lambda s : [itos[i] for i in s]\n",
        "print(encode('jpt-3'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBgMrUpLt8k9",
        "outputId": "83e96a5d-8436-426f-813f-495992447528"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[48, 54, 58, 7, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(encode(text))\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "253WHxrWt8eB",
        "outputId": "379214ba-ac4c-43ca-9114-3fbde45bf1dc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1115394,) int64\n",
            "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
            "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
            " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
            "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
            "  0 37 53 59]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "Suno3XjYt8af"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = 8\n",
        "train_data[:context_length+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Fmttn92t8XP",
        "outputId": "35f79691-f64c-4bfc-8d48-1c7dd28d35f6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:context_length]\n",
        "y = train_data[1:context_length+1]\n",
        "for i in range(context_length):\n",
        "  context=x[:i+1]\n",
        "  target = y[i]\n",
        "  print(f'When the input is {context}The output should be {target}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEwk5Vt3t8Ud",
        "outputId": "1be4f39f-3cee-49c0-f75a-0ecb4b9541b3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When the input is [18]The output should be 47\n",
            "When the input is [18 47]The output should be 56\n",
            "When the input is [18 47 56]The output should be 57\n",
            "When the input is [18 47 56 57]The output should be 58\n",
            "When the input is [18 47 56 57 58]The output should be 1\n",
            "When the input is [18 47 56 57 58  1]The output should be 15\n",
            "When the input is [18 47 56 57 58  1 15]The output should be 47\n",
            "When the input is [18 47 56 57 58  1 15 47]The output should be 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "context_length = 8\n",
        "def get_batch(split):\n",
        "  data = train_data if split == 'train' else val_data\n",
        "  list_of_ints = [i for i in range(len(data) - context_length + 1)]\n",
        "  ix = rd.sample(list_of_ints, batch_size)\n",
        "  x = np.stack([data[i:i + context_length] for i in ix])  # Utilisation d'une liste en compréhension\n",
        "  y = np.stack([data[i + 1:i + context_length + 1] for i in ix])  # Idem pour y\n",
        "  return x, y\n",
        "\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('Inputs')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('Targets')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "print('____________________________________')\n",
        "for b in range(batch_size):\n",
        "  for t in range(context_length):\n",
        "    context = xb[b,:t+1]\n",
        "    target = yb[b,t]\n",
        "    print(f\"When input is {context.tolist()} the output should be {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U-_CFJHt8Qr",
        "outputId": "991bb4e0-20ed-4b69-e6c2-d5ed97e3408d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs\n",
            "(4, 8)\n",
            "[[ 1 39 57 47 42 43  1 58]\n",
            " [54 56 43 58 58 63  1 54]\n",
            " [ 1 46 47 57  1 42 39 59]\n",
            " [43  1 40 43 57 58  2  1]]\n",
            "Targets\n",
            "(4, 8)\n",
            "[[39 57 47 42 43  1 58 46]\n",
            " [56 43 58 58 63  1 54 43]\n",
            " [46 47 57  1 42 39 59 45]\n",
            " [ 1 40 43 57 58  2  1 32]]\n",
            "____________________________________\n",
            "When input is [1] the output should be 39\n",
            "When input is [1, 39] the output should be 57\n",
            "When input is [1, 39, 57] the output should be 47\n",
            "When input is [1, 39, 57, 47] the output should be 42\n",
            "When input is [1, 39, 57, 47, 42] the output should be 43\n",
            "When input is [1, 39, 57, 47, 42, 43] the output should be 1\n",
            "When input is [1, 39, 57, 47, 42, 43, 1] the output should be 58\n",
            "When input is [1, 39, 57, 47, 42, 43, 1, 58] the output should be 46\n",
            "When input is [54] the output should be 56\n",
            "When input is [54, 56] the output should be 43\n",
            "When input is [54, 56, 43] the output should be 58\n",
            "When input is [54, 56, 43, 58] the output should be 58\n",
            "When input is [54, 56, 43, 58, 58] the output should be 63\n",
            "When input is [54, 56, 43, 58, 58, 63] the output should be 1\n",
            "When input is [54, 56, 43, 58, 58, 63, 1] the output should be 54\n",
            "When input is [54, 56, 43, 58, 58, 63, 1, 54] the output should be 43\n",
            "When input is [1] the output should be 46\n",
            "When input is [1, 46] the output should be 47\n",
            "When input is [1, 46, 47] the output should be 57\n",
            "When input is [1, 46, 47, 57] the output should be 1\n",
            "When input is [1, 46, 47, 57, 1] the output should be 42\n",
            "When input is [1, 46, 47, 57, 1, 42] the output should be 39\n",
            "When input is [1, 46, 47, 57, 1, 42, 39] the output should be 59\n",
            "When input is [1, 46, 47, 57, 1, 42, 39, 59] the output should be 45\n",
            "When input is [43] the output should be 1\n",
            "When input is [43, 1] the output should be 40\n",
            "When input is [43, 1, 40] the output should be 43\n",
            "When input is [43, 1, 40, 43] the output should be 57\n",
            "When input is [43, 1, 40, 43, 57] the output should be 58\n",
            "When input is [43, 1, 40, 43, 57, 58] the output should be 2\n",
            "When input is [43, 1, 40, 43, 57, 58, 2] the output should be 1\n",
            "When input is [43, 1, 40, 43, 57, 58, 2, 1] the output should be 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = get_batch('train')\n",
        "print('Inputs')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('Targets')\n",
        "print(yb.shape)\n",
        "print(yb)\n"
      ],
      "metadata": {
        "id": "OqvKmtK8t8Ki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb2866ef-4be5-45ba-836b-ae086b19712b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs\n",
            "(4, 8)\n",
            "[[39 57 59 56 43  8  0  0]\n",
            " [63  8  0  0 13 33 18 21]\n",
            " [49 43  1 39 52  1 43 62]\n",
            " [43 51 40 43 56  1 61 43]]\n",
            "Targets\n",
            "(4, 8)\n",
            "[[57 59 56 43  8  0  0 15]\n",
            " [ 8  0  0 13 33 18 21 16]\n",
            " [43  1 39 52  1 43 62 43]\n",
            " [51 40 43 56  1 61 43 50]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_probability as tfp"
      ],
      "metadata": {
        "id": "t3aD4XyKt8ID"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageModel(tf.Module):\n",
        "  def __init__(self,vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = tf.Variable(tf.random.normal([vocab_size,vocab_size]))\n",
        "  def __call__(self,idx,targets =None):\n",
        "    logits = tf.nn.embedding_lookup(self.token_embedding_table,idx)\n",
        "    if targets is None:\n",
        "      loss= None\n",
        "    else :\n",
        "      B,T,C = logits.shape\n",
        "      logits = tf.reshape(logits,[B*T,C])\n",
        "      targets = tf.reshape(targets,[B*T])\n",
        "      loss = tf.keras.losses.sparse_categorical_crossentropy(targets,logits,from_logits=True)\n",
        "    return(logits,tf.reduce_mean(loss))\n",
        "  def generate(self,idx,max_new_tokens):\n",
        "    for i in range(max_new_tokens):\n",
        "      logits,loss = self(idx)\n",
        "      logits = logits [:,-1,:]\n",
        "      probs = tf.nn.softmax(logits)\n",
        "      idx_next = tfp.Multinomial(probs=probs,size=1)\n",
        "      idx = tf.concat([(idx), (idx_next)],axis=1)\n",
        "      return(idx)\n",
        "\n",
        "m=BigramLanguageModel(vocab_size)\n",
        "out=m(xb,yb)\n",
        "print(out[0].shape)\n",
        "print(out[1].shape)\n",
        "print(\"Logits:\", out[0])\n",
        "print(\"Loss:\", out[1])\n",
        "print(decode(m.generate(np.zeros(1,dtype=np.int32),max_new_tokens = 100)[0].tolist()))"
      ],
      "metadata": {
        "id": "lsdjkj8wt8Nv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "01ef6f41-f468-45e7-8388-889f4da3f52b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 65)\n",
            "()\n",
            "Logits: tf.Tensor(\n",
            "[[ 2.2926724  -1.7428583   0.4850148  ... -1.5406622  -1.3667842\n",
            "  -0.89780337]\n",
            " [ 0.6049428  -0.37285373 -0.03189395 ... -0.19215085  0.55007637\n",
            "   0.34815136]\n",
            " [ 0.42745182  0.2451142  -0.82166874 ... -0.90642893 -0.03507071\n",
            "  -0.24629602]\n",
            " ...\n",
            " [ 0.22609127 -0.77244824  1.6175609  ... -0.37875894 -2.5461874\n",
            "   0.4740015 ]\n",
            " [-0.80830777 -0.55427396 -0.26638216 ...  0.8952034   0.6210111\n",
            "  -1.3505417 ]\n",
            " [-0.9685111   0.9451213   0.906063   ...  0.7674658   0.20205861\n",
            "  -2.234185  ]], shape=(32, 65), dtype=float32)\n",
            "Loss: tf.Tensor(4.5306177, shape=(), dtype=float32)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-748731af6b12>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Logits:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_new_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-748731af6b12>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, idx, max_new_tokens)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-748731af6b12>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A4Y1Yd9ft8FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c8T3C1Int8Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ghpsocKSt7_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7mkVZd7lt78G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hipo2em6t74j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YFUr7_tct71d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jQRo9N75t7yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sIrt-Xhot7vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GkF_RKkCt7s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vohqOS2Bt7qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hMjrHTvOt7n-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jLIXkw1Wt7lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7lN281Hmt7jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q4Dg8iz_t7gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C2K7e5v8t7ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5DabuWbUt7bu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}